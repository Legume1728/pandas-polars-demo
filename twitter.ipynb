{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/legume/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import polars as pl\n",
    "import time\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10_000, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Tweet_ID</th><th>Username</th><th>Text</th><th>Retweets</th><th>Likes</th><th>Timestamp</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>i64</td><td>i64</td><td>str</td></tr></thead><tbody><tr><td>1</td><td>&quot;julie81&quot;</td><td>&quot;Party least receive say or sin…</td><td>2</td><td>25</td><td>&quot;2023-01-30 11:00:51&quot;</td></tr><tr><td>2</td><td>&quot;richardhester&quot;</td><td>&quot;Hotel still Congress may membe…</td><td>35</td><td>29</td><td>&quot;2023-01-02 22:45:58&quot;</td></tr><tr><td>3</td><td>&quot;williamsjoseph&quot;</td><td>&quot;Nice be her debate industry th…</td><td>51</td><td>25</td><td>&quot;2023-01-18 11:25:19&quot;</td></tr><tr><td>4</td><td>&quot;danielsmary&quot;</td><td>&quot;Laugh explain situation career…</td><td>37</td><td>18</td><td>&quot;2023-04-10 22:06:29&quot;</td></tr><tr><td>5</td><td>&quot;carlwarren&quot;</td><td>&quot;Involve sense former often app…</td><td>27</td><td>80</td><td>&quot;2023-01-24 07:12:21&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>9996</td><td>&quot;ntate&quot;</td><td>&quot;Agree reflect military box abi…</td><td>81</td><td>86</td><td>&quot;2023-01-15 11:46:20&quot;</td></tr><tr><td>9997</td><td>&quot;garrisonjoshua&quot;</td><td>&quot;Born which push still. Degree …</td><td>73</td><td>100</td><td>&quot;2023-05-06 00:46:54&quot;</td></tr><tr><td>9998</td><td>&quot;adriennejackson&quot;</td><td>&quot;You day agent likely region. T…</td><td>10</td><td>62</td><td>&quot;2023-02-27 14:55:08&quot;</td></tr><tr><td>9999</td><td>&quot;kcarlson&quot;</td><td>&quot;Guess without successful save.…</td><td>21</td><td>60</td><td>&quot;2023-01-09 16:09:35&quot;</td></tr><tr><td>10000</td><td>&quot;vdickerson&quot;</td><td>&quot;Body onto understand team abou…</td><td>65</td><td>54</td><td>&quot;2023-04-19 01:35:56&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10_000, 6)\n",
       "┌──────────┬─────────────────┬────────────────────────────┬──────────┬───────┬─────────────────────┐\n",
       "│ Tweet_ID ┆ Username        ┆ Text                       ┆ Retweets ┆ Likes ┆ Timestamp           │\n",
       "│ ---      ┆ ---             ┆ ---                        ┆ ---      ┆ ---   ┆ ---                 │\n",
       "│ i64      ┆ str             ┆ str                        ┆ i64      ┆ i64   ┆ str                 │\n",
       "╞══════════╪═════════════════╪════════════════════════════╪══════════╪═══════╪═════════════════════╡\n",
       "│ 1        ┆ julie81         ┆ Party least receive say or ┆ 2        ┆ 25    ┆ 2023-01-30 11:00:51 │\n",
       "│          ┆                 ┆ sin…                       ┆          ┆       ┆                     │\n",
       "│ 2        ┆ richardhester   ┆ Hotel still Congress may   ┆ 35       ┆ 29    ┆ 2023-01-02 22:45:58 │\n",
       "│          ┆                 ┆ membe…                     ┆          ┆       ┆                     │\n",
       "│ 3        ┆ williamsjoseph  ┆ Nice be her debate         ┆ 51       ┆ 25    ┆ 2023-01-18 11:25:19 │\n",
       "│          ┆                 ┆ industry th…               ┆          ┆       ┆                     │\n",
       "│ 4        ┆ danielsmary     ┆ Laugh explain situation    ┆ 37       ┆ 18    ┆ 2023-04-10 22:06:29 │\n",
       "│          ┆                 ┆ career…                    ┆          ┆       ┆                     │\n",
       "│ 5        ┆ carlwarren      ┆ Involve sense former often ┆ 27       ┆ 80    ┆ 2023-01-24 07:12:21 │\n",
       "│          ┆                 ┆ app…                       ┆          ┆       ┆                     │\n",
       "│ …        ┆ …               ┆ …                          ┆ …        ┆ …     ┆ …                   │\n",
       "│ 9996     ┆ ntate           ┆ Agree reflect military box ┆ 81       ┆ 86    ┆ 2023-01-15 11:46:20 │\n",
       "│          ┆                 ┆ abi…                       ┆          ┆       ┆                     │\n",
       "│ 9997     ┆ garrisonjoshua  ┆ Born which push still.     ┆ 73       ┆ 100   ┆ 2023-05-06 00:46:54 │\n",
       "│          ┆                 ┆ Degree …                   ┆          ┆       ┆                     │\n",
       "│ 9998     ┆ adriennejackson ┆ You day agent likely       ┆ 10       ┆ 62    ┆ 2023-02-27 14:55:08 │\n",
       "│          ┆                 ┆ region. T…                 ┆          ┆       ┆                     │\n",
       "│ 9999     ┆ kcarlson        ┆ Guess without successful   ┆ 21       ┆ 60    ┆ 2023-01-09 16:09:35 │\n",
       "│          ┆                 ┆ save.…                     ┆          ┆       ┆                     │\n",
       "│ 10000    ┆ vdickerson      ┆ Body onto understand team  ┆ 65       ┆ 54    ┆ 2023-04-19 01:35:56 │\n",
       "│          ┆                 ┆ abou…                      ┆          ┆       ┆                     │\n",
       "└──────────┴─────────────────┴────────────────────────────┴──────────┴───────┴─────────────────────┘"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pl.read_csv('./twitter_dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed: 0.032 s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "words_ordered_df = (\n",
    "    df.lazy().with_columns(\n",
    "        pl.col('Text').str.to_lowercase()\n",
    "            .str.extract_all('\\w+')\n",
    "            .list.unique()\n",
    "            .alias('words')\n",
    "    )\n",
    "        .select(['Likes', 'words'])\n",
    "        .explode('words')\n",
    "        .filter(~pl.col('words').is_in(stop_words))\n",
    "        .group_by('words')\n",
    "        .agg(pl.sum('Likes').alias('likes'))\n",
    "        .sort('likes', descending=True)\n",
    "        .collect()\n",
    ")\n",
    "\n",
    "print(f'elapsed: {time.time() - t0:.3f} s')\n",
    "words_ordered_df.head(100).write_csv('top_words.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>words</th><th>likes</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;hard&quot;</td><td>20628</td></tr><tr><td>&quot;maybe&quot;</td><td>20209</td></tr><tr><td>&quot;man&quot;</td><td>20150</td></tr><tr><td>&quot;exactly&quot;</td><td>20056</td></tr><tr><td>&quot;everyone&quot;</td><td>19958</td></tr><tr><td>&quot;boy&quot;</td><td>19845</td></tr><tr><td>&quot;teach&quot;</td><td>19845</td></tr><tr><td>&quot;tax&quot;</td><td>19713</td></tr><tr><td>&quot;instead&quot;</td><td>19706</td></tr><tr><td>&quot;team&quot;</td><td>19690</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 2)\n",
       "┌──────────┬───────┐\n",
       "│ words    ┆ likes │\n",
       "│ ---      ┆ ---   │\n",
       "│ str      ┆ i64   │\n",
       "╞══════════╪═══════╡\n",
       "│ hard     ┆ 20628 │\n",
       "│ maybe    ┆ 20209 │\n",
       "│ man      ┆ 20150 │\n",
       "│ exactly  ┆ 20056 │\n",
       "│ everyone ┆ 19958 │\n",
       "│ boy      ┆ 19845 │\n",
       "│ teach    ┆ 19845 │\n",
       "│ tax      ┆ 19713 │\n",
       "│ instead  ┆ 19706 │\n",
       "│ team     ┆ 19690 │\n",
       "└──────────┴───────┘"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_ordered_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
